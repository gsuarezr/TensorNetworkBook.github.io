
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1. Capítulo 1 &#8212; Introduccion a las Redes tensoriales</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="1. Pendientes" href="pendientes.html" />
    <link rel="prev" title="Bienvenidos a introducción a las redes tensoriales" href="introduccion.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      <img src="_static/logo.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduccion a las Redes tensoriales</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <p class="caption">
 <span class="caption-text">
  Preliminares
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   1. Capítulo 1
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Info para el grupo
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="pendientes.html">
   1. Pendientes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="planificacion.html">
   2. Logística
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="conducta.html">
   4. Código de Conducta
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="estilo.html">
   5. Estilo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bibliografia.html">
   6. Bibliografía
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/capitulo1.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/mcditoos/TensorNetworkBook.github.io"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        <a class="edit-button" href="https://github.com/mcditoos/TensorNetworkBook.github.io/edit/main//RedesTensoriales/capitulo1.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduccion">
   1.1. Introducción
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#que-es-un-tensor">
   1.2. ¿Que es un Tensor?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#representacion-grafica-de-redes-tensoriales">
     1.2.1. Representacion gráfica de redes tensoriales
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#redes-tensoriales-para-sistemas-cuanticos-de-muchos-cuerpos">
   1.3. Redes tensoriales para sistemas cuánticos de muchos cuerpos
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#redes-tensoriales-mps">
     1.3.1. Redes Tensoriales MPS
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="capitulo-1">
<h1><span class="section-number">1. </span>Capítulo 1<a class="headerlink" href="#capitulo-1" title="Permalink to this headline">¶</a></h1>
<blockquote class="epigraph">
<div><p><strong>“Ser ignorante no es tan penoso como no estar dispuesto a aprender.”</strong><br /></p>
<p>– Benjamin Franklin</p>
</div></blockquote>
<div class="section" id="introduccion">
<h2><span class="section-number">1.1. </span>Introducción<a class="headerlink" href="#introduccion" title="Permalink to this headline">¶</a></h2>
<p>Las redes tensoriales son un concepto relativamente joven que tiene su origen en la notación gráfica de Penrose, la cual comenzó a aplicarse en problemas prácticos en 1971 <span id="id1">[<a class="reference internal" href="#id10"><span>Pen71</span></a>]</span>. Sin embargo, permaneció fuera de los temas populares en ciencia hasta que Deutsch uso la notación diagramática proveniente de ella, para formular lo que llamó redes computacionales cuánticas que se conocen hoy en día como circuitos cuánticos <span id="id2">[<a class="reference internal" href="#id17"><span>Deu89</span></a>]</span>. ¡Así es! Los circuitos que generas en <span class="xref myst">Qiskit</span> son un caso especial de redes tensoriales. Un dato curioso es que mientras que el modelo que se popularizó es el de Deustsch, Feynman había formulado otro modelo diagramático relacionado con este un poco antes <span id="id3">[<a class="reference internal" href="#id16"><span>Fey86</span></a>]</span>. Sin embargo, incluso después de ello no se habló mucho de redes tensoriales.</p>
<p>El interés resurge gracias al uso de la teoría de redes tensoriales para cálculos numéricos con el nacimiento de algoritmos como MPS, TT, TTN, MERA y PEPS. Varios de ellos tienen su origen en materia condensada y se pensaron para resolver problemas en mecánica cuántica, un poco inspirados en el grupo de renormalización de la matriz densidad. Sin embargo, estas técnicas numéricas también han encontrado aplicaciones en machine learning, debido a que, al igual que en materia condensada,  los problemas numéricos son de alta dimensión, incluso llevando a empresas como Google a invertir en la investigación de estos temas y el desarrollo de librerías para el cálculo numérico de estas técnicas como <a class="reference external" href="https://github.com/google/TensorNetwork">TensorNetwork</a>.</p>
<p>Una red tensorial es un arreglo contable de tensores conectados por contracciones (suma de índices) entre ellos, y no solo han ayudado en la comprensión teórica de las funciones de onda cuántica, sino que también forman la base de muchos potentes enfoques de simulación numérica. Entonces… ¿de qué trata este libro? El escrito a continuación trata de lo que se suelen llamar “métodos de redes tensoriales” que es el conjunto de herramientas asociadas al cálculo y simplificación de redes tensoriales. Estos métodos además de ser usados en las areas ya mencionadas de física de la materia condensada <span id="id4">[<a class="reference internal" href="#id14"><span>Eis13</span></a>]</span> y machine learning <span id="id5">[<a class="reference internal" href="#id11"><span>NPOV15</span></a>]</span>, también están presentes en información cuántica <span id="id6">[<a class="reference internal" href="#id15"><span>PC20</span></a>]</span>, open quantum systems <span id="id7">[<a class="reference internal" href="#id13"><span>dPSchroderC+18</span></a>]</span>, gravedad cuántica <span id="id8">[<a class="reference internal" href="#id12"><span>COZ18</span></a>]</span> y muchas otras áreas de la ciencia.</p>
<p>En este capítulo, introduciremos algunos de los conceptos básicos que son necesarios para entender lo que es una red tensorial, y como las técnicas de esta teoría pueden ser usadas en cálculos numéricos. Comenzaremos por lo primero que debemos entender, que es un tensor.</p>
</div>
<div class="section" id="que-es-un-tensor">
<h2><span class="section-number">1.2. </span>¿Que es un Tensor?<a class="headerlink" href="#que-es-un-tensor" title="Permalink to this headline">¶</a></h2>
<p>Un tensor es un arreglo multidimensional de números complejos, este concepto matemático generaliza la idea de mapas multilineales, es decir funciones de muchos parámetros que son lineales con respecto a cada uno de ellos. Ahora bien, si después de esta definición un tanto formal no te ha quedado claro, intentemos con una versión un poco más intuitiva.</p>
<p>Un tensor es una serie de números denotados con <span class="math notranslate nohighlight">\(N\)</span> índices, donde <span class="math notranslate nohighlight">\(N\)</span> es lo que llamamos el orden del tensor. Todos hemos tratado con tensores en nuestra vida, por ejemplo:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(5\)</span> es un tensor de rango <span class="math notranslate nohighlight">\(0\)</span>, es una serie de numeros para la cual no necesitamos indices para referirnos a un elemento, pasa lo mismo para cualquier escalar</p></li>
<li><p>El vector <span class="math notranslate nohighlight">\(\vec{T}=\begin{pmatrix} 0  \\ 1 \end{pmatrix}\)</span>, es un tensor de rango <span class="math notranslate nohighlight">\(1\)</span>, necesitamos un indice para referirnos a alguno de sus elementos (i.e <span class="math notranslate nohighlight">\(i=1,2\)</span>)</p></li>
</ul>
<a class="reference internal image-reference" href="_images/vector.png"><img alt="vector" class="align-center" src="_images/vector.png" style="width: 200px;" /></a>
<ul class="simple">
<li><p>Una matriz <span class="math notranslate nohighlight">\(\vec{T}=\begin{pmatrix} 0 &amp; 0 \\1 &amp; 1 \end{pmatrix}\)</span> es un tensor de rango <span class="math notranslate nohighlight">\(2\)</span>, necesitamos 2 índices para identificar inequivocamente cada uno de sus elementos</p></li>
</ul>
<a class="reference internal image-reference" href="_images/matriz.png"><img alt="matriz" class="align-center" src="_images/matriz.png" style="width: 200px;" /></a>
<ul class="simple">
<li><p>Un tensor de rango 3 es un objeto matemático con el que la mayoría de las personas están menos familiarizadas, pero imaginemos unos números ordenados en un cubo de rubik, para referirnos a ellos se necesitarían 3 índices.</p></li>
</ul>
<a class="reference internal image-reference" href="_images/tensor.png"><img alt="Tensor de rango 3" class="align-center" src="_images/tensor.png" style="width: 200px;" /></a>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p>Nombre</p></th>
<th class="text-align:center head"><p>Ejemplo</p></th>
<th class="text-align:center head"><p>Rango</p></th>
<th class="text-align:center head"><p>Notacion</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p>Escalar</p></td>
<td class="text-align:center"><p>Constante</p></td>
<td class="text-align:center"><p>0</p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\lambda\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>Vector</p></td>
<td class="text-align:center"><p>Funcion de onda</p></td>
<td class="text-align:center"><p>1</p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\psi_{i}\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>Matriz</p></td>
<td class="text-align:center"><p>Operador</p></td>
<td class="text-align:center"><p>2</p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(A_{i.j}\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>: :</p></td>
<td class="text-align:center"><p>: :</p></td>
<td class="text-align:center"><p>: :</p></td>
<td class="text-align:center"><p>: :</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>Tensor Rango-N</p></td>
<td class="text-align:center"><p>Funcion de onda para N-cuerpos</p></td>
<td class="text-align:center"><p>N</p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\psi_{\alpha_{1},...\alpha_{N}}\)</span></p></td>
</tr>
</tbody>
</table>
<p>La manera en la que se suele tratar con los tensores en física y matemática, es mediante lo que se conoce como notación indicial y el convenio de suma de Einstein, las cuales introduciremos en la próxima sección</p>
<div class="section" id="representacion-grafica-de-redes-tensoriales">
<h3><span class="section-number">1.2.1. </span>Representacion gráfica de redes tensoriales<a class="headerlink" href="#representacion-grafica-de-redes-tensoriales" title="Permalink to this headline">¶</a></h3>
<p>Utilizamos una notación de diagramas para los tensores, donde cada tensor es dibujado como una figura sólida con un número de conexiones correspondientes a su orden. A continuación mostramos unos ejemplos:</p>
<p><strong>El Vector</strong> <span class="math notranslate nohighlight">\(A_{i}\)</span> se representa como:</p>
<a class="reference internal image-reference" href="_images/vector_tensor.png"><img alt="Un vector en su representación gráfica" class="align-center" src="_images/vector_tensor.png" style="width: 140px;" /></a>
<p><strong>La matriz</strong> <span class="math notranslate nohighlight">\(B_{ij}\)</span> se representa como:</p>
<a class="reference internal image-reference" href="_images/matrix_tensor.png"><img alt="Una matríz en su representación gráfica" class="align-center" src="_images/matrix_tensor.png" style="width: 140px;" /></a>
<p><strong>Un tensor de orden 3</strong> <span class="math notranslate nohighlight">\(C_{ijk}\)</span> se representa como:</p>
<a class="reference internal image-reference" href="_images/tensor_orden_3.png"><img alt="Un tensor de orden 3 en su representación gráfica" class="align-center" src="_images/tensor_orden_3.png" style="width: 140px;" /></a>
<p>Podemos formar redes de múltiples tensores donde un índice compartido por dos tensores denota una suma o contracción sobre el índice.</p>
<a class="reference internal image-reference" href="_images/contraccion.png"><img alt="Representación gráfica de una contracción entre dos tensores" class="align-center" src="_images/contraccion.png" style="width: 270px;" /></a>
<p>La multiplicación de dos matrices <span class="math notranslate nohighlight">\(A\)</span> y <span class="math notranslate nohighlight">\(B\)</span> se puede detonar en forma de suma como:
<span class="math notranslate nohighlight">\(C_{ik} = \sum_{j}A_{ij}B_{jk} \)</span>. Su equivalente en diagramas de tensores es:</p>
<a class="reference internal image-reference" href="_images/ejemplo1.png"><img alt="Representación gráfica de una contracción entre dos tensores, denotando una multiplicación de matrices" class="align-center" src="_images/ejemplo1.png" style="width: 270px;" /></a>
<p>De similar manera, podemos pensar en cómo representar otras operaciones comunes con matrices, como el producto interno. Si ahora consideramos dos vectores <span class="math notranslate nohighlight">\(A\)</span> y <span class="math notranslate nohighlight">\(B\)</span>, su producto interno <span class="math notranslate nohighlight">\(\sum_{i}A_{i}\cdot B_{i}\)</span> va a tener un equivalente en diagramas de tensores de forma:</p>
<a class="reference internal image-reference" href="_images/prod_interno1.png"><img alt="Representación gráfica de un producto interno con vectores" class="align-center" src="_images/prod_interno1.png" style="width: 270px;" /></a>
<p>Con dos tensores <span class="math notranslate nohighlight">\(D\)</span> y <span class="math notranslate nohighlight">\(E\)</span> de rango 4 por ejemplo su producto interno <span class="math notranslate nohighlight">\(\sum_{ijkl}D_{ijkl}\cdot E_{ijkl}\)</span> es equivalente al diagrama:</p>
<a class="reference internal image-reference" href="_images/prod_interno2.png"><img alt="Representación gráfica de un producto interno con tensores rango-4" class="align-center" src="_images/prod_interno2.png" style="width: 270px;" /></a>
<p>Finalmente, también podemos representar la traza de un arreglo. Considerando una matriz <span class="math notranslate nohighlight">\(A\)</span>, su traza <span class="math notranslate nohighlight">\(\sum_{i}A_{ii}\)</span> tiene un diagrama equivalente con la forma:</p>
<a class="reference internal image-reference" href="_images/traza.png"><img alt="Representación gráfica de la traza de una matriz" class="align-center" src="_images/traza.png" style="width: 270px;" /></a>
<p>Podemos ver el poder de la notación con diagramas de tensores en la contracción de 3 tensores, donde en notación de sumatoria se expresa como:
<span class="math notranslate nohighlight">\(D_{ijk} = \sum_{lmn}A_{ljm}B_{iln}C_{nmk} \)</span>. En cambio la notacion con diagramas es mucho mas sencilla de interpretar:</p>
<a class="reference internal image-reference" href="_images/ejemplo2.png"><img alt="Representación gráfica de una contracción entre tres tensores" class="align-center" src="_images/ejemplo2.png" style="width: 270px;" /></a>
<p>En muchas aplicaciones, la meta es aproximar un tensor de alto orden, como el siguiente:</p>
<a class="reference internal image-reference" href="_images/tensor_N.png"><img alt="Tensor de orden N" class="align-center" src="_images/tensor_N.png" style="width: 270px;" /></a>
<p>A un red tensorial compuesta de muchos tensores de bajo orden:</p>
<a class="reference internal image-reference" href="_images/tensor_N_2.png"><img alt="Red tensorial de N tensores de bajo orden" class="align-center" src="_images/tensor_N_2.png" style="width: 270px;" /></a>
<p>La representación de redes tensoriales es muy útil por varias razones:</p>
<ol class="simple">
<li><p>Pueden ofrecer una representación más comprimida de estructuras de datos grandes</p></li>
<li><p>Permite una caracterización de la estructura de los datos. Además de que la notación de diagramas permite una intuición visual más clara.</p></li>
<li><p>Ya que la descomposición de los datos es robusta, se pueden utilizar para trabajar con ruido o con datos faltantes.</p></li>
<li><p>Permite tener un Framework unificado para manipular grandes datos. Como evaluar información estadística utilizando una colección pequeña de redes tensoriales sin la necesitada de tener conocimiento específico sobre la estructura de todo el sistema o de lo que representa.</p></li>
</ol>
<p>La <strong>teoría de redes tensoriales</strong> se enfoca en entender como esta representación funciona y en que situaciones es más óptima utilizarla. En cambio, los <strong>algoritmos de redes tensoriales</strong> se enfocan en métodos para obtener , manipular y extraer información de estas representaciones.</p>
</div>
</div>
<div class="section" id="redes-tensoriales-para-sistemas-cuanticos-de-muchos-cuerpos">
<h2><span class="section-number">1.3. </span>Redes tensoriales para sistemas cuánticos de muchos cuerpos<a class="headerlink" href="#redes-tensoriales-para-sistemas-cuanticos-de-muchos-cuerpos" title="Permalink to this headline">¶</a></h2>
<div class="section" id="redes-tensoriales-mps">
<h3><span class="section-number">1.3.1. </span>Redes Tensoriales MPS<a class="headerlink" href="#redes-tensoriales-mps" title="Permalink to this headline">¶</a></h3>
<p>También conocidas como Tensor Train (TT), las redes tensoriales <strong>Matrix Product State</strong> son una manera de representar un tensor de rango-<span class="math notranslate nohighlight">\(N\)</span> como una cadena de tensores de rango-<span class="math notranslate nohighlight">\(3\)</span>. Esta representación es el objetivo de muchos algoritmos debido a que provee una buena aproximación de las redes tensoriales y es más eficiente computacionalmente.</p>
<a class="reference internal image-reference" href="_images/MPS.png"><img alt="Ejecución de MPS como un recorte del Tensor objetivo en tensores más pequeños" class="align-center" src="_images/MPS.png" style="width: 470px;" /></a>
<p>Viendo está imagen puede ser difícil imaginarnos de donde viene dicha eficiencia, pero vayamos más a fondo. Recordemos que el estado cuántico <span class="math notranslate nohighlight">\(|\psi\rangle=\sum_{ij\dots k}\psi_{ij\dots k}|u_{ij\dots k}\rangle\)</span> requiere de <span class="math notranslate nohighlight">\(2^n\)</span> coeficientes independientes para ser descrito completamente, es decir, crece exponencialmente con el tamaño de n. Con MPS queremos poder describir al estado cómo:</p>
<div class="math notranslate nohighlight">
\[|\psi\rangle = \sum_{ij\dots k}Tr(A_{i}^{[1]}A_{j}^{[2]}\dots A_{k}^{[n]})|u_{ijkl}\rangle\]</div>
<p>De esta manera los recursos necesarios para describirlo solo crecen linealmente con un factor de escalamiento de <span class="math notranslate nohighlight">\(nd\chi^{2}\)</span> donde <span class="math notranslate nohighlight">\(d\)</span> es la dimensión del subsistema y <span class="math notranslate nohighlight">\(\chi\)</span> por <span class="math notranslate nohighlight">\(\chi\)</span> es el limite superior de las matrices. Podemos observar en esta ecuación que conocer los componentes de <span class="math notranslate nohighlight">\(\psi\)</span> solo es cosa de calcular el producto entre las matrices. Es de aquí de donde viene el nombre del método.</p>
<p>La capacidad de MPS de reducir los recursos viene de una herramienta llamada <strong>Singular Value Decomposition</strong> que se aplica de manera recursiva al tensor inicial <span class="math notranslate nohighlight">\(T\)</span> para obtener las matrices que cumplen <span class="math notranslate nohighlight">\(T=U\Sigma V\)</span>, donde <span class="math notranslate nohighlight">\(U\)</span> y <span class="math notranslate nohighlight">\(V\)</span> son unitarios y <span class="math notranslate nohighlight">\(\Sigma\)</span> es real, diagonal y no-negativa.</p>
<p>Si volvemos al ejemplo de la imagen, podemos notar que los tensores de los extremos solo tienen dos conexiones, por lo que el producto va a dar como resultado un escalar entonces la traza no es necesaria. Y su ecuación tendria la forma:
$<span class="math notranslate nohighlight">\(|\psi\rangle = \sum_{ijkl}A_{i}^{[1]}A_{j}^{[2]}A_{k}^{[3]}A_{l}^{[4]}|u_{ij\dots k}\rangle\)</span>$</p>
<p id="id9"><dl class="citation">
<dt class="label" id="id12"><span class="brackets"><a class="fn-backref" href="#id8">COZ18</a></span></dt>
<dd><p>Goffredo Chirco, Daniele Oriti, and Mingyi Zhang. Group field theory and tensor networks: towards a ryu–takayanagi formula in full quantum gravity. <em>Classical and Quantum Gravity</em>, 35(11):115011, may 2018. URL: <a class="reference external" href="https://doi.org/10.1088/1361-6382/aabf55">https://doi.org/10.1088/1361-6382/aabf55</a>, <a class="reference external" href="https://doi.org/10.1088/1361-6382/aabf55">doi:10.1088/1361-6382/aabf55</a>.</p>
</dd>
<dt class="label" id="id13"><span class="brackets"><a class="fn-backref" href="#id7">dPSchroderC+18</a></span></dt>
<dd><p>Javier del Pino, Florian A. Y. N. Schröder, Alex W. Chin, Johannes Feist, and Francisco J. Garcia-Vidal. Tensor network simulation of non-markovian dynamics in organic polaritons. <em>Phys. Rev. Lett.</em>, 121:227401, Nov 2018. URL: <a class="reference external" href="https://link.aps.org/doi/10.1103/PhysRevLett.121.227401">https://link.aps.org/doi/10.1103/PhysRevLett.121.227401</a>, <a class="reference external" href="https://doi.org/10.1103/PhysRevLett.121.227401">doi:10.1103/PhysRevLett.121.227401</a>.</p>
</dd>
<dt class="label" id="id17"><span class="brackets"><a class="fn-backref" href="#id2">Deu89</a></span></dt>
<dd><p>David Elieser Deutsch. Quantum computational networks. <em>Proceedings of the Royal Society of London. A. Mathematical and Physical Sciences</em>, 425(1868):73–90, September 1989. URL: <a class="reference external" href="https://doi.org/10.1098/rspa.1989.0099">https://doi.org/10.1098/rspa.1989.0099</a>, <a class="reference external" href="https://doi.org/10.1098/rspa.1989.0099">doi:10.1098/rspa.1989.0099</a>.</p>
</dd>
<dt class="label" id="id14"><span class="brackets"><a class="fn-backref" href="#id4">Eis13</a></span></dt>
<dd><p>J. Eisert. Entanglement and tensor network states. <em>Modeling and Simulation 3, 520 (2013)</em>, 2013. <a class="reference external" href="https://arxiv.org/abs/arXiv:1308.3318">arXiv:arXiv:1308.3318</a>.</p>
</dd>
<dt class="label" id="id16"><span class="brackets"><a class="fn-backref" href="#id3">Fey86</a></span></dt>
<dd><p>Richard Feynman. Quantum mechanical computers. <em>Foundations of Physics</em>, 16(6):507–531, June 1986. URL: <a class="reference external" href="https://doi.org/10.1007/bf01886518">https://doi.org/10.1007/bf01886518</a>, <a class="reference external" href="https://doi.org/10.1007/bf01886518">doi:10.1007/bf01886518</a>.</p>
</dd>
<dt class="label" id="id11"><span class="brackets"><a class="fn-backref" href="#id5">NPOV15</a></span></dt>
<dd><p>Alexander Novikov, Dmitrii Podoprikhin, Anton Osokin, and Dmitry P Vetrov. Tensorizing neural networks. In C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett, editors, <em>Advances in Neural Information Processing Systems</em>, volume 28. Curran Associates, Inc., 2015. URL: <a class="reference external" href="https://proceedings.neurips.cc/paper/2015/file/6855456e2fe46a9d49d3d3af4f57443d-Paper.pdf">https://proceedings.neurips.cc/paper/2015/file/6855456e2fe46a9d49d3d3af4f57443d-Paper.pdf</a>.</p>
</dd>
<dt class="label" id="id10"><span class="brackets"><a class="fn-backref" href="#id1">Pen71</a></span></dt>
<dd><p>Roger Penrose. Applications of negative dimensional tensors. <em>Academic Press</em>, 1971.</p>
</dd>
<dt class="label" id="id15"><span class="brackets"><a class="fn-backref" href="#id6">PC20</a></span></dt>
<dd><p>Lorenzo Piroli and J. Ignacio Cirac. Quantum cellular automata, tensor networks, and area laws. <em>Phys. Rev. Lett.</em>, 125:190402, Nov 2020. URL: <a class="reference external" href="https://link.aps.org/doi/10.1103/PhysRevLett.125.190402">https://link.aps.org/doi/10.1103/PhysRevLett.125.190402</a>, <a class="reference external" href="https://doi.org/10.1103/PhysRevLett.125.190402">doi:10.1103/PhysRevLett.125.190402</a>.</p>
</dd>
</dl>
</p>
<!--- 



## Notacion indicial y convenio de la suma de Einstein 


Esta introduccion a la notacion indicial y la suma de einstein sera un poco distinta de la usual ya que estaremos revisando tres formas de ver estas manipulaciones, una que llamaremos algebraica (usada en relatividad), la diagramatica que aun no tiene estandar pero que llamaremos de Penrose siguiendo [articulo de biamonte] y la de dirac (usualmente usada en cuantica). Esto nos dara una perspectiva mas amplia al poder apreciar las ventajas y desventajas de cada una de ellas, y resaltar lo intuitiva que es la notacion grafica.









</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="introduccion.html" title="previous page">Bienvenidos a introducción a las redes tensoriales</a>
    <a class='right-next' id="next-link" href="pendientes.html" title="next page"><span class="section-number">1. </span>Pendientes</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Comunidad sin nombre<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>